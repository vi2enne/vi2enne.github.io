<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Vivienne H. Wang</title>

  <meta name="author" content="Vivienne H. Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>
<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Vivienne Huiling Wang</name>
              </p>
              <div align="justify">
              <p>
                I am a Postdoctoral Researcher in the <a href="https://rl.aalto.fi/"> Aalto Robot Learning Lab</a> working with <a href="https://people.aalto.fi/joni.pajarinen"> Joni Pajarinen</a>. I did my PhD in the <a href="https://rl.aalto.fi/"> Robot Learning Lab</a> of Aalto University and <a href="https://research.tuni.fi/vision/">Computer Vision Group</a> of Tampere University, supervised by Joni Pajarinen and <a href="https://webpages.tuni.fi/vision/public_pages/JoniKamarainen/index.html"> Joni Kämäräinen</a>. My recent research mainly explores novel algorithms for <strong> Reinforcement Learning</strong>. 

              </p>
              <p>
                During 2015-2016, I worked as research assistant in Deep Learning and Bayesian Modeling group of Aalto University, supervised by Tapani Raiko and Juha Karhunen. I worked as research intern in Nokia Research Center in 2013-2014. I have published on top venues such as ICML, ICLR, AAAI, IJCAI and one US patent in the related fields, and received one IEEE best paper award in ICME 2015. My research publications in collaboration with Nokia scientists have won Nokia Labs Award in 2016 and 2017. I serve as senior reviewer of RLC 2025, PC Member and reviewer of AAAI 2020-2025, ICLR 2024-2025, NeurIPS 2022-2025 and ICML 2022-2025 etc.
              </p>
              <p style="text-align:center">
                <a href="mailto:vivienne.wang@aalto.fi">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.fi/citations?user=hN0MLgYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/vi2enne/">Github</a>&nbsp/&nbsp
                <a href="https://www.linkedin.com/in/vivienne-huiling-wang-78974974/">LinkedIn</a>
              </p>
              </div>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm generally interested in reinforcement learning, deep learning, 2D/3D computer vision.

                <strong>Selected papers and patent</strong> are listed as follows. <strong>Full list</strong> of publications can be found in my <a href="https://scholar.google.fi/citations?user=hN0MLgYAAAAJ&hl=en">Google Scholar</a> page.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                          <img src="images/icml25.png" alt="ICML25" width="160" style="border-style: none">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                          <a href="xxx">
                          <papertitle>Hierarchical Reinforcement Learning with Uncertainty-Guided Diffusional Subgoals</papertitle>
                          </a>
                          <br>
                          <strong>Vivienne Huiling Wang</strong>,
                          Tinghuai Wang,
                          Joni Pajarinen
                          <br>
                          <em> The Forty-second International Conference on Machine Learning (ICML)</em>, 2025
                          <br>
                          <p></p>
                          <p> A GP-regularized hierarchical diffusion policy models uncertainty to generate subgoals, improving sample efficiency and control performance. </p>
            </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="images/iclr25.png" alt="ICLR25" width="160" style="border-style: none">
                          </td>
                          <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="xxx">
                            <papertitle>Multi-Scale Fusion for Object Representation</papertitle>
                            </a>
                            <br>
                            Rongzhen Zhao, 
                            <strong>Vivienne Huiling Wang</strong>,
                            Juho Kannala,
                            Joni Pajarinen
                            <br>
                            <em> International Conference on Learning Representations (ICLR) </em>, 2025
                            <br>
                            <p></p>
                            <p> We propose Multi-Scale Fusion (MSF) to enhance VAE guidance for Object-Centric Learning (OCL) training. </p>
              </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                              <img src="images/mm25.png" alt="MM25" width="160" style="border-style: none">
                            </td>
                            <td style="padding:20px;width:75%;vertical-align:middle">
                              <a href="xxx">
                              <papertitle>Vector-Quantized Vision Foundation Models for Object-Centric Learning.</papertitle>
                              </a>
                              <br>
                              Rongzhen Zhao, 
                              <strong>Vivienne Huiling Wang</strong>,
                              Juho Kannala,
                              Joni Pajarinen
                              <br>
                              <em> ACM International Conference on Multimedia (ACM MM) </em>, 2025
                              <br>
                              <p></p>
                              <p> We propose simple yet effective unified architecture for OCL, which outperforms baselines in object discovery and recognition, as well as downstream visual prediction and reasoning. </p>
                </td>
                </tr>

                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                                <img src="images/thesis.png" alt="Thesis" width="160" style="border-style: none">
                              </td>
                              <td style="padding:20px;width:75%;vertical-align:middle">
                                <a href="xxx">
                                <papertitle>Robust Visual Perception and Decision Making for Autonomous Systems.</papertitle>
                                </a>
                                <br>
                                <strong>Vivienne Huiling Wang</strong>
                                <br>
                                <em> Doctoral Dissertation </em>, 2025
                                <br>
                                <p></p>
                                <p> This thesis endeavors to push the frontiers of visual perception and decision making capabilities for autonomous systems. Through contributions in video object segmentation and hierarchical reinforcement learning, it sets the stage for the development of more robust and dependable autonomous systems, thereby paving the way for their wider and safer application in society. </p>
                  </td>
                  </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                          <img src="images/icml24.png" alt="ICML24" width="160" style="border-style: none">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                          <a href="xxx">
                          <papertitle>Probabilistic Subgoal Representations for Hierarchical Reinforcement Learning</papertitle>
                          </a>
                          <br>
                          <strong>Vivienne Huiling Wang</strong>,
                          Tinghuai Wang,
                          Wenyan Yang,
                          Joni-Kristian Kämäräinen,
                          Joni Pajarinen
                          <br>
                          <em> The Forty-first International Conference on Machine Learning (ICML)</em>, 2024
                          <br>
                          <p></p>
                          <p>We propose a new Gaussian processes (GPs) based method for learning probabilistic subgoal representations in Hierarchical Reinforcement Learning (HRL).</p>
            </td>
            </tr>

        <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
                      <img src="images/agile.png" alt="Arxiv" width="160" style="border-style: none">
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26213/25985">
                      <papertitle> State-Conditioned Adversarial Subgoal Generation</papertitle>
                      </a>
                      <br>
                      <strong>Vivienne Huiling Wang</strong>,
                      Joni Pajarinen,
                      Tinghuai Wang,
                      Joni-Kristian Kämäräinen
                      <br>
                      <em> Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI)</em>, 2023
                      <br>
                      <a href="https://arxiv.org/pdf/2201.09635.pdf">pdf</a>
                      <p></p>
                      <p>We propose a novel adversarially guided subgoal generation framework for goal-conditioned HRL to mitigate the issue of non-stationarity in off-policy training.</p>
        </td>
        </tr>

<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ijcai17.png" alt="IJCAI17" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.ijcai.org/Proceedings/2017/0634.pdf">
              <papertitle>Cross-Granularity Graph Inference for Semantic Video Object Segmentation</papertitle>
              </a>
              <br>
              <strong>Huiling Wang</strong>,
              Tinghuai Wang,
              Ke Chen,
              Joni-Kristian Kämäräinen
              <br>
              <em>International Joint Conference on Artificial Intelligence (IJCAI)</em>, 2017
              <br>
              <a href="https://www.ijcai.org/Proceedings/2017/0634.pdf">pdf</a>
              /
              <a href="https://www.youtube.com/watch?v=0QwewAUcGLI&feature=emb_logo">video</a>
              <p></p>
              <p>We address semantic video object segmentation
via a novel cross-granularity hierarchical graphical
model to integrate tracklet and object proposal reasoning with superpixel labeling.</p>
</td>
</tr>

<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cviu16.png" alt="CVIU16" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S1077314215002507">
              <papertitle>Primary Object Discovery and Segmentation in Videos via Graph-Based Transductive Inference</papertitle>
              </a>
              <br>
              <strong>Huiling Wang</strong>,
              Tinghuai Wang
              <br>
              <em>Computer Vision and Image Understanding (CVIU)</em>, 2016
              <br>
              <a href="data/cviu16.pdf">pdf</a>
              <p></p>
              <p>We present a novel algorithm that detects recurring primary object and learns cohort object proposals over space-time in video. Our core contribution is a graph transduction process that exploits both appearance cues learned from rudimentary detections of object-like regions, and the intrinsic structures within video data.</p>
</td>
</tr>

<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/accv2016.png" alt="ACCV16" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1606.02280.pdf">
              <papertitle>Semi-Supervised Domain Adaptation for Weakly Labeled Semantic Video Object Segmentation</papertitle>
              </a>
              <br>
              <strong>Huiling Wang</strong>,
              Tapani Raiko,
              Lasse Lensu,
              Tinghuai Wang,
              Juha Karhunen
              <br>
              <em>Asian Conference on Computer Vision (ACCV)</em>, 2016
              <br>
              <a href="https://arxiv.org/pdf/1606.02280.pdf">pdf</a>
              <p></p>
              <p>We propose a semi-supervised approach to adapting CNN image recognition model trained from labeled image data to the target domain exploiting both semantic evidence learned from CNN, and the intrinsic structures of video data.</p>
</td>
</tr>

                    <tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/nc15.jpg" alt="NC15" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S092523121500836X">
              <papertitle>A Weakly Supervised Geodesic Level Set Framework for Interactive Image Segmentation</papertitle>
              </a>
              <br>
              Tinghuai Wang,
              <strong>Huiling Wang</strong>,
              Lixin Fan
              <br>
              <em>Neurocomputing</em>, 2015
              <br>
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S092523121500836X">pdf</a>
              <p></p>
              <p> We combine geodesic distance information with the flexibility of level set methods in energy minimization, leveraging the complementary strengths of each to promote accurate boundary placement and strong region connectivity while requiring less user interaction.  </p>
</td>
</tr>


        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Recent Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>

            <td width="75%" valign="center">
              Reviewer, NeurIPS 2022-2025
              <br><br>
              Reviewer, ICML 2022-2025
              <br><br>
              Reviewer, ICLR 2025
              <br><br>
              Program Committee, AAAI 2020-2025
            </td>
          </tr>
        </tbody></table>
</body>
</html>
